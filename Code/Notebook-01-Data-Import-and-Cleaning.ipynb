{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports:\n",
    "# ...\n",
    "import numpy as np\n",
    "# Data Wrangling, Cleaning, Reading from file\n",
    "import pandas as pd\n",
    "# Hypothesis Testing\n",
    "from random import randint\n",
    "# Vizualizations:\n",
    "import matplotlib.pyplot as plt\n",
    "# Vizualizations: \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import & Cleaning\n",
    "\n",
    "Import the datasets that you selected for this project and go through the following steps at a minimum. You are welcome to do further cleaning as you feel necessary:\n",
    "1. Display the data: print the first 5 rows of each dataframe to your Jupyter notebook.\n",
    "2. Check for missing values.\n",
    "3. Check for any obvious issues with the observations (keep in mind the minimum & maximum possible values for each test/subtest).\n",
    "4. Fix any errors you identified in steps 2-3.\n",
    "5. Display the data types of each feature.\n",
    "6. Fix any incorrect data types found in step 5.\n",
    "    - Fix any individual values preventing other columns from being the appropriate type.\n",
    "    - If your dataset has a column of percents (ex. '50%', '30.5%', etc.), use the function you wrote in Part 1 (coding challenges, number 3) to convert this to floats! *Hint*: use `.map()` or `.apply()`.\n",
    "7. Rename Columns.\n",
    "    - Column names should be all lowercase.\n",
    "    - Column names should not contain spaces (underscores will suffice--this allows for using the `df.column_name` method to access columns in addition to `df['column_name']`).\n",
    "    - Column names should be unique and informative.\n",
    "8. Drop unnecessary rows (if needed).\n",
    "9. Merge dataframes that can be merged.\n",
    "10. Perform any additional cleaning that you feel is necessary.\n",
    "11. Save your cleaned and merged dataframes as csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code:\n",
    "#Import Data Sets\n",
    "actdf = pd.read_csv('../data/act_2019_ca.csv') #2019 ACT Scores in California by School\n",
    "satdf = pd.read_csv('../data/sat_2019_ca.csv') #2019 SAT Scores in California by School\n",
    "equitydf = pd.read_csv('../data/equitable_county_rank.csv') #2019 California School District Equitablility Ranking\n",
    "\n",
    "#Display Data\n",
    "print(actdf.head())\n",
    "print(satdf.head())\n",
    "print(equitydf.head())\n",
    "\n",
    "#Drop the empty (last) row\n",
    "actdf.drop(actdf.tail(1).index,inplace=True)\n",
    "satdf.drop(satdf.tail(1).index,inplace=True)\n",
    "\n",
    "#RType == 'C' entries contain aggregate County info\n",
    "act_countydf = actdf[actdf['RType'] == 'C'].copy()\n",
    "sat_countydf = satdf[satdf['RType'] == 'C'].copy()\n",
    "\n",
    "#RType == 'D' entries contain aggregate School District info\n",
    "act_districtdf = actdf[actdf['RType'] == 'D'].copy()\n",
    "sat_districtdf = satdf[satdf['RType'] == 'D'].copy()\n",
    "\n",
    "#Create filters for special cases where score records are not available(or don't exist)\n",
    "#Filter out DISTRICT records where no seniors took exam, but more than 15 were enrolled\n",
    "null_district_actdf = act_districtdf[act_districtdf['PctGE21'].isnull()==False]\n",
    "null_district_satdf = sat_districtdf[sat_districtdf['PctBothBenchmark12'].isnull()==False]\n",
    "\n",
    "#Filter out COUNTY records where no seniors took exam, but more than 15 were enrolled\n",
    "null_county_actdf = act_countydf[act_countydf['PctGE21'].isnull()==False]\n",
    "null_county_satdf = sat_countydf[sat_countydf['PctBothBenchmark12'].isnull()==False]\n",
    "\n",
    "#Filter out DISTRICT records where less than 15 enrolled seniors took exam\n",
    "district_scores_actdf = null_district_actdf[null_district_actdf['PctGE21']!='*'].copy()\n",
    "district_scores_satdf = null_district_satdf[null_district_satdf['PctBothBenchmark12']!='*'].copy()\n",
    "\n",
    "#Filter out COUNTY records where less than 15 enrolled seniors took exam\n",
    "county_scores_actdf = null_county_actdf[null_county_actdf['PctGE21']!='*'].copy()\n",
    "county_scores_satdf = null_county_satdf[null_county_satdf['PctBothBenchmark12']!='*'].copy()\n",
    "\n",
    "#Drop special characters '$' and ',' from equitable_county_rank.csv\n",
    "for row in range(len(equitydf.index)):\n",
    "    equitydf.loc[row,['Expenditures for Public Elementary and Secondary Schools per Pupil']] \\\n",
    "        = equitydf['Expenditures for Public Elementary and Secondary Schools per Pupil'][row].replace(',','').replace('$','')\n",
    "    equitydf.loc[row,['Income by School District']] = equitydf['Income by School District'][row].replace(',','').replace('$','')\n",
    "\n",
    "    #Display datatypes\n",
    "print(sat_districtdf.dtypes)\n",
    "print(act_districtdf.dtypes)\n",
    "print(district_scores_actdf.dtypes)\n",
    "print(district_scores_satdf.dtypes)\n",
    "print(equitydf.dtypes)\n",
    "\n",
    "#Fix Incorrect Data Types\n",
    "for name in ['Expenditures for Public Elementary and Secondary Schools per Pupil', 'Income by School District']:\n",
    "    equitydf[name] = equitydf[name].apply(int).copy()\n",
    "\n",
    "for name in ['CCode', 'CDCode', 'Enroll12', 'NumTstTakr']:\n",
    "    act_districtdf[name] = act_districtdf[name].apply(int).copy()\n",
    "    act_countydf[name] = act_countydf[name].apply(int).copy()\n",
    "    district_scores_actdf[name] = district_scores_actdf[name].apply(int).copy()\n",
    "    county_scores_actdf[name] = county_scores_actdf[name].apply(int).copy()\n",
    "    \n",
    "for name in ['CCode', 'CDCode', 'Enroll12', 'NumTSTTakr12']:\n",
    "    sat_districtdf[name] = sat_districtdf[name].apply(int).copy()\n",
    "    sat_countydf[name] = sat_countydf[name].apply(int).copy()\n",
    "    district_scores_satdf[name] = district_scores_satdf[name].apply(int).copy()\n",
    "    county_scores_satdf[name] = county_scores_satdf[name].apply(int).copy()\n",
    "\n",
    "#Additional dtypes to fix for 'PctGE21'-(ACT data) & 'PctBothBenchmark12'-(SAT data)\n",
    "county_scores_actdf['NumGE21'] = county_scores_actdf['NumGE21'].apply(int)\n",
    "district_scores_actdf['NumGE21'] = district_scores_actdf['NumGE21'].apply(int)\n",
    "\n",
    "county_scores_actdf['PctGE21'] = county_scores_actdf['PctGE21'].apply(float)\n",
    "district_scores_actdf['PctGE21'] = district_scores_actdf['PctGE21'].apply(float)\n",
    "\n",
    "county_scores_satdf['NumTSTTakr12'] = county_scores_satdf['NumTSTTakr12'].apply(int)\n",
    "district_scores_satdf['NumTSTTakr12'] = district_scores_satdf['NumTSTTakr12'].apply(int)\n",
    "\n",
    "county_scores_satdf['TotNumBothBenchmark12'] = county_scores_satdf['TotNumBothBenchmark12'].apply(int)\n",
    "district_scores_satdf['TotNumBothBenchmark12'] = district_scores_satdf['TotNumBothBenchmark12'].apply(int)\n",
    "\n",
    "county_scores_satdf['PctBothBenchmark12'] = county_scores_satdf['PctBothBenchmark12'].apply(float)\n",
    "district_scores_satdf['PctBothBenchmark12'] = district_scores_satdf['PctBothBenchmark12'].apply(float)\n",
    "\n",
    "district_scores_actdf['PctGE21'] = district_scores_actdf['PctGE21'].apply(float)\n",
    "\n",
    "#Remove excess columns and just focus on DISTRICT data for the sake of time\n",
    "act_districtdf=act_districtdf[['CCode', 'CDCode','DName', 'CName','Enroll12', 'NumTstTakr']]\n",
    "district_scores_actdf=district_scores_actdf[['CCode', 'CDCode','DName', 'CName','Enroll12', 'NumTstTakr', 'NumGE21', 'PctGE21']]\n",
    "\n",
    "sat_districtdf = sat_districtdf[['CCode', 'CDCode', 'DName', 'CName','Enroll12', 'NumTSTTakr12']]\n",
    "district_scores_satdf = district_scores_satdf[['CCode', 'CDCode', 'DName', 'CName','Enroll12', 'NumTSTTakr12', 'TotNumBothBenchmark12', 'PctBothBenchmark12']]\n",
    "\n",
    "#Rename Columns\n",
    "act_districtdf = act_districtdf.rename(columns={'CCode':'county_code','CName':'county_name','CDCode':'district_code', 'DName':'district_name','Enroll12':'enrolled_seniors', 'NumTstTakr':'tested_seniors'})\n",
    "district_scores_actdf = district_scores_actdf.rename(columns={'CCode':'county_code','CName':'county_name','CDCode':'district_code', 'DName':'district_name','Enroll12':'enrolled_seniors', 'NumTstTakr':'tested_seniors', 'NumGE21':'num_over_benchmark_act', 'PctGE21':'pct_over_benchmark_act'})\n",
    "\n",
    "sat_districtdf = sat_districtdf.rename(columns={'CCode':'county_code','CName':'county_name', 'CDCode':'district_code', 'DName':'district_name','Enroll12':'enrolled_seniors', 'NumTSTTakr12':'tested_seniors'})\n",
    "district_scores_satdf = district_scores_satdf.rename(columns={'CCode':'county_code','CName':'county_name', 'CDCode':'district_code', 'DName':'district_name','Enroll12':'enrolled_seniors', 'NumTSTTakr12':'tested_seniors', 'TotNumBothBenchmark12':'num_over_benchmark_sat', 'PctBothBenchmark12':'pct_over_benchmark_sat'})\n",
    "    \n",
    "equitydf = equitydf.rename(columns={'Rank*':'rank', 'School District':'district_name', 'Score':'score','Expenditures for Public Elementary and Secondary Schools per Pupil':'expenditures_per_pupil','Income by School District':'income'})\n",
    "\n",
    "#Additional Cleaning\n",
    "#ID equitable counties from respective districts\n",
    "#Drop 'School District' from the string containing the School District name\n",
    "for index in range(len(equitydf['district_name'])):\n",
    "    equitydf.loc[ index, [ 'district_name' ] ]  = equitydf['district_name'][index].replace('School District','')\n",
    "    \n",
    "#Hov helped me merge by sowing me str.strip() and giving insiight into the underlying problem\n",
    "standardized_test = district_scores_satdf.merge(district_scores_actdf, on='district_name')\n",
    "standardized_test['district_name'] = standardized_test['district_name'].str.strip()\n",
    "standardized_test['district_name'] = standardized_test['district_name'].str.lower()\n",
    "equitydf['district_name'] = equitydf['district_name'].str.strip()\n",
    "equitydf['district_name'] = equitydf['district_name'].str.lower()\n",
    "finaldf = standardized_test.merge(equitydf, on='district_name')\n",
    "finaldf[ ['district_name', 'num_over_benchmark_sat', 'num_over_benchmark_act','pct_over_benchmark_sat','pct_over_benchmark_act','rank', 'score']].describe()\n",
    "\n",
    "#Save your cleaned and merged dataframes as csv files.\n",
    "finaldf.to_csv('./finaldf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
